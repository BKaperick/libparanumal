     
#define cubeThreadsP \
  for(iint k=0;k<p_NqP;++k;inner2) \
    for(iint j=0;j<p_NqP;++j;inner1) \
      for(iint i=0;i<p_NqP;++i;inner0) 

#if 0
// q  \in  Nq x Nq x Nq x Nelements
// Pq \in  NqPx NqPx NqPx Nelements

//                        |         | 
// form invP, P wrt   o x x x x x x x x o
//                        |         |

// 1D transforms (assume J=const)
//  S = (lambda*W + hScaling*trans(D)*W*D) // stiffness matrix (also needs assembly)
//
//  S~ = W\S = W\trans(D)*W*D
//  S~ = V*Mu*inv(V) [ [V,Mu] = eig(S~) ]
//
//  S = W*V*(lambda*I+hScaling*Mu)*inv(V)
//
// inv(S) = V*(lambda*I + hScaling*Mu)^{-1}*inv(W*V)
//
// invP := inv(W*V)
// P = V
//
// inv(S) = P*(lambda*I + hscaling*Mu)^{-1}*invP

// 1. multiply by invP in each direcction
// 2. divide nodewise by  (lambda + Mu_i/h_r^2 + Mu_j/h_s^2 + Mu_k/h_t^2)*h_r*h_s*h_t/8 for suitable h_r,h_s,h_t
//    use h_r = 1/min r_x ? give or take a factor of 2
// 3. multiply by P in each direction
#endif


kernel void ellipticOasPreconHex3D(const iint Nelements,
				   const iint   * restrict vmapPP,
				   const iint   * restrict faceNodesP,
				   const dfloat * restrict forward,
				   const dfloat * restrict diagInvOp,
				   const dfloat * restrict back,
				   const dfloat * restrict q,
				   dfloat * restrict Pq){
  
  for(iint e=0; e<Nelements; ++e; outer0){
    
    shared dfloat s_q[p_NqP][p_NqP][p_NqP];
    shared dfloat s_forward[p_NqP][p_NqP];
    shared dfloat s_back[p_NqP][p_NqP];
    exclusive dfloat r_tmp, r_diagInvOp;
    
    cubeThreadsP{

      iint n=i+p_NqP*j+p_NqP*p_NqP*k;

      s_q[0][0][n] = 0; // zero shared memory
    }

    barrier(localMemFence);
    
    cubeThreadsP{

      iint n=i+p_NqP*j+p_NqP*p_NqP*k;
    
      if(n<p_Np){
	// coalesce reads from p_Nq x p_Nq x p_Nq storage
	iint ip = n%p_Nq;
	iint jp = (n/p_Nq)%p_Nq;
	iint kp = (n/(p_Nq*p_Nq));
	s_q[kp+1][jp+1][ip+1] = q[n+e*p_Np];
      }

      r_diagInvOp = diagInvOp[n+e*p_NpP];

      if(k==0) s_forward[j][i]  = forward[i+p_NqP*j];
      if(k==1) s_back[j][i]     = back[i+p_NqP*j];

      // thread safe since the overlap nodes do not overlap
      while(n<p_Nfp*p_Nfaces){
	const iint id = vmapPP[n+e*p_Nfaces*p_Nfp];
	s_q[0][0][faceNodesP[n]] = q[id];
	n+=p_NqP*p_NqP*p_NqP;
      }
    }
      
    barrier(localMemFence);

    // r-transform
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_forward[i][n]*s_q[k][j][n];

      r_tmp = tmp;
    }

    barrier(localMemFence);

    cubeThreadsP{
      s_q[k][j][i] = r_tmp;
    }

    barrier(localMemFence);

    // s-transform
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_forward[j][n]*s_q[k][n][i];
      
      r_tmp = tmp;
    }

    barrier(localMemFence);

    cubeThreadsP{
      s_q[k][j][i] = r_tmp;
    }

    barrier(localMemFence);

    // t-transform 
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_forward[k][n]*s_q[n][j][i];

      // diagonal inverse
      r_tmp = r_diagInvOp*tmp;
      //      r_tmp = tmp;
    }

    barrier(localMemFence);

    cubeThreadsP{
      s_q[k][j][i] = r_tmp;
    }

    barrier(localMemFence);

    // t-transform back
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_back[k][n]*s_q[n][j][i];
      
      r_tmp = tmp;
    }

    barrier(localMemFence);
    
    cubeThreadsP{
      s_q[k][j][i] = r_tmp;
    }

    barrier(localMemFence);
    
    // s-transform back
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_back[j][n]*s_q[k][n][i];
      
      r_tmp = tmp;
    }

    barrier(localMemFence);
    
    cubeThreadsP{
      s_q[k][j][i] = r_tmp;
    }

    barrier(localMemFence);

    // r-transform back
    cubeThreadsP{
      dfloat tmp = 0.f;
      for(iint n=0;n<p_NqP;++n)
	tmp += s_back[i][n]*s_q[k][j][n];
      
      const iint id=i+p_NqP*j+p_NqP*p_NqP*k + p_NpP*e;
      Pq[id] = tmp;
    }
  }
}
					
  
